{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robingenz/htwg-machine-learning-exercises/blob/main/exercises/02_Linear_Regression/03_naive_bayes_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAjCEVrKwLuv"
      },
      "source": [
        "# Naiver Bayesklassifikator\n",
        "\n",
        "## Setup\n",
        "\n",
        "### Einbinden von Paketen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7rsOwie3wLuv",
        "outputId": "34399a0c-1e9f-4916-9f13-0423853143b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1.23.4', '1.5.0', '1.1.3', '0.19.3')"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import skimage\n",
        "import math\n",
        "%matplotlib inline\n",
        "\n",
        "np.__version__, pd.__version__, sklearn.__version__, skimage.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The version_information extension is already loaded. To reload it, use:\n",
            "  %reload_ext version_information\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "Software versions": [
                {
                  "module": "Python",
                  "version": "3.10.8 64bit [GCC 10.2.1 20210110]"
                },
                {
                  "module": "IPython",
                  "version": "8.6.0"
                },
                {
                  "module": "OS",
                  "version": "Linux 5.10.104 linuxkit aarch64 with glibc2.31"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.10.8 64bit [GCC 10.2.1 20210110]</td></tr><tr><td>IPython</td><td>8.6.0</td></tr><tr><td>OS</td><td>Linux 5.10.104 linuxkit aarch64 with glibc2.31</td></tr><tr><td colspan='2'>Sun Nov 13 22:45:07 2022 UTC</td></tr></table>"
            ],
            "text/latex": [
              "\\begin{tabular}{|l|l|}\\hline\n",
              "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
              "Python & 3.10.8 64bit [GCC 10.2.1 20210110] \\\\ \\hline\n",
              "IPython & 8.6.0 \\\\ \\hline\n",
              "OS & Linux 5.10.104 linuxkit aarch64 with glibc2.31 \\\\ \\hline\n",
              "\\hline \\multicolumn{2}{|l|}{Sun Nov 13 22:45:07 2022 UTC} \\\\ \\hline\n",
              "\\end{tabular}\n"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.10.8 64bit [GCC 10.2.1 20210110]\n",
              "IPython 8.6.0\n",
              "OS Linux 5.10.104 linuxkit aarch64 with glibc2.31\n",
              "Sun Nov 13 22:45:07 2022 UTC"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%load_ext version_information\n",
        "%version_information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aufgabe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sun Nov 13 22:45:07 UTC 2022']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import tarfile\n",
        "\n",
        "tgz_file_path = 'data/lfw-funneled.tgz'\n",
        "data_dir_path = 'data/lfw_funneled'\n",
        "\n",
        "# Herunterladen des Datensatzes\n",
        "if not os.path.isfile(tgz_file_path):\n",
        "    print(\"Downloading...\")\n",
        "    urlretrieve('http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz', filename = tgz_file_path)\n",
        "    print(\"Download finished.\")\n",
        "\n",
        "dateDownloaded = !date #Calling Linux\n",
        "print(dateDownloaded)\n",
        "\n",
        "# Entpacken des Datensatzes\n",
        "if not os.path.isdir(data_dir_path):\n",
        "    print(\"Extracting...\")\n",
        "    tar = tarfile.open(tgz_file_path, 'r:gz')\n",
        "    tar.extractall(path='data/')\n",
        "    tar.close()\n",
        "    print(\"Extract finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finden von Personen mit **70 oder mehr** Bildern:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7 persons with ≥ 70 images.\n"
          ]
        }
      ],
      "source": [
        "person_dir_paths = []\n",
        "for subdir, _, files in os.walk(data_dir_path):\n",
        "    if len(files) >= 70:\n",
        "        person_dir_paths.append(subdir)\n",
        "\n",
        "print('Found', len(person_dir_paths), 'persons with ≥ 70 images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Datensatz in 60% Trainings- und 40% Testbilder aufteilen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitted into 516 test images and 772 training images.\n"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "image_paths = []\n",
        "image_name_indexes = []\n",
        "\n",
        "for i, person_dir_path in enumerate(person_dir_paths):\n",
        "    files = sorted(listdir(person_dir_path))\n",
        "    for file in files:\n",
        "        image_name_indexes.append(i)\n",
        "        image_paths.append(f'{person_dir_path}/{file}')\n",
        "\n",
        "# x_training_image_path -> image paths\n",
        "# y_training_name_index -> 0,1,2,3,4,5,6\n",
        "# x_test_image_path -> image paths\n",
        "# y_test_name_index -> 0,1,2,3,4,5,6\n",
        "x_training_image_path, x_test_image_path, y_training_name_index, y_test_name_index = train_test_split(image_paths, image_name_indexes, test_size=0.4, random_state=0)\n",
        "\n",
        "print('Splitted into', len(x_test_image_path), 'test images and', len(x_training_image_path), 'training images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vorverarbeitung der Bilder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage import io, util, transform\n",
        "\n",
        "def show_image(image):\n",
        "    io.imshow(image) \n",
        "    io.show()\n",
        "\n",
        "def load_image_from_path(path, as_gray=True):\n",
        "    image = io.imread(path, as_gray=as_gray)\n",
        "    return image\n",
        "\n",
        "def transform_image(image):\n",
        "    image = util.crop(image, ((100,70), (80,80))) # Values are based on first image of Hugo_Chavez\n",
        "    image = transform.resize(image, (32,32))\n",
        "    # show_image(image)\n",
        "    image = np.hstack(image)\n",
        "    return image\n",
        "\n",
        "def create_image_stack(image):\n",
        "    stack = np.hstack(image)\n",
        "    return stack\n",
        "\n",
        "x_training_images = []\n",
        "x_training_stacks = []\n",
        "for training_image_path in x_training_image_path:\n",
        "    image = load_image_from_path(training_image_path)\n",
        "    x_training_images.append(image)\n",
        "    image = transform_image(image)\n",
        "    stack = create_image_stack(image)\n",
        "    x_training_stacks.append(stack)\n",
        "x_training_matrix = np.asarray(x_training_stacks)\n",
        "\n",
        "x_test_images = []\n",
        "x_test_stacks = []\n",
        "for test_image_path in x_test_image_path:\n",
        "    image = load_image_from_path(test_image_path)\n",
        "    x_test_images.append(image)\n",
        "    image = transform_image(image)\n",
        "    stack = create_image_stack(image)\n",
        "    x_test_stacks.append(stack)\n",
        "x_test_matrix = np.asarray(x_test_stacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anwendung der **Hauptkomponentenanalyse**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import decomposition\n",
        "\n",
        "pca = decomposition.PCA(n_components=7, whiten=True)\n",
        "pca.fit(x_training_matrix)\n",
        "\n",
        "x_training_projections = pca.transform(x_training_matrix)\n",
        "x_test_projections = pca.transform(x_test_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_indexes(indexes):\n",
        "    return [1 if index == 3 else -1 for index in indexes] # George_W_Bush is index 3\n",
        "\n",
        "def evaluate_prediction(prediction_indexes, observation_indexes):\n",
        "    prediction_labels = label_indexes(prediction_indexes)\n",
        "    observation_labels = label_indexes(observation_indexes)\n",
        "\n",
        "    true_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_negatives = 0\n",
        "    false_positives = 0\n",
        "\n",
        "    for i in range(len(prediction_indexes)):\n",
        "        prediction_label = prediction_labels[i]\n",
        "        observation_label = observation_labels[i]\n",
        "        if prediction_label == 1 and observation_label == 1:\n",
        "            true_positives += 1\n",
        "        if prediction_label == 1 and observation_label == -1:\n",
        "            false_positives += 1\n",
        "        if prediction_label == -1 and observation_label == -1:\n",
        "            true_negatives += 1\n",
        "        if prediction_label == -1 and observation_label == 1:\n",
        "            false_negatives += 1\n",
        "\n",
        "    print('True Positives Rate:', round(100 * true_positives / (true_positives + false_negatives)), '%')\n",
        "    print('False Negatives Rate:', round(100 * false_negatives / (true_positives + false_negatives)), '%')\n",
        "    print('True Negatives Rate:', round(100 * true_negatives / (true_negatives + false_positives)), '%')\n",
        "    print('False Positives Rate:', round(100 * false_positives / (false_positives + true_negatives)), '%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data\n",
            "True Positives Rate: 81 %\n",
            "False Negatives Rate: 19 %\n",
            "True Negatives Rate: 49 %\n",
            "False Positives Rate: 51 %\n",
            "\n",
            "\n",
            "Training data\n",
            "True Positives Rate: 84 %\n",
            "False Negatives Rate: 16 %\n",
            "True Negatives Rate: 53 %\n",
            "False Positives Rate: 47 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Test data\n",
        "print('Test data')\n",
        "y_test_prediction = gnb.fit(x_training_projections, y_training_name_index).predict(x_test_projections)\n",
        "evaluate_prediction(y_test_prediction, y_test_name_index)\n",
        "print('\\n')\n",
        "\n",
        "# Training data\n",
        "print('Training data')\n",
        "y_train_prediction = gnb.fit(x_training_projections, y_training_name_index).predict(x_training_projections)\n",
        "evaluate_prediction(y_train_prediction, y_training_name_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data\n",
            "True Positives Rate: 86 %\n",
            "False Negatives Rate: 14 %\n",
            "True Negatives Rate: 43 %\n",
            "False Positives Rate: 57 %\n",
            "\n",
            "\n",
            "Training data\n",
            "True Positives Rate: 88 %\n",
            "False Negatives Rate: 12 %\n",
            "True Negatives Rate: 45 %\n",
            "False Positives Rate: 55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vscode/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
            "/home/vscode/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# See: https://github.com/tigju/Naive-Bayes-Classifier-from-scratch/blob/main/naive_bayes.ipynb\n",
        "class NaiveBayesClassifier():\n",
        "\n",
        "    def calc_prior(self, features, target):\n",
        "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
        "        return self.prior\n",
        "\n",
        "    def calc_statistics(self, features, targets):\n",
        "        self.mean = features.groupby(targets).apply(np.mean).to_numpy()\n",
        "        self.var = features.groupby(targets).apply(np.var).to_numpy()\n",
        "        return self.mean, self.var\n",
        "\n",
        "    def gaussian_density(self, class_idx, x):\n",
        "        mean = self.mean[class_idx]\n",
        "        var = self.var[class_idx]\n",
        "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
        "        denominator = np.sqrt(2 * np.pi * var)\n",
        "        prob = numerator / denominator\n",
        "        return prob\n",
        "\n",
        "    def calc_posterior(self, x):\n",
        "        posteriors = []\n",
        "        for i in range(self.count):\n",
        "            prior = np.log(self.prior[i])\n",
        "            conditional = np.sum(np.log(self.gaussian_density(i, x)))\n",
        "            posterior = prior + conditional\n",
        "            posteriors.append(posterior)\n",
        "        return self.classes[np.argmax(posteriors)]\n",
        "\n",
        "    def fit(self, features, targets):\n",
        "        self.classes = np.unique(targets)\n",
        "        self.count = len(self.classes)\n",
        "        self.feature_nums = features.shape[1]\n",
        "        self.rows = features.shape[0]\n",
        "        self.calc_statistics(features, targets)\n",
        "        self.calc_prior(features, targets)\n",
        "\n",
        "    def predict(self, features):\n",
        "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
        "        return preds\n",
        "\n",
        "nbc = NaiveBayesClassifier()\n",
        "\n",
        "# Test data\n",
        "print('Test data')\n",
        "x_training_projections_df = pd.DataFrame(x_training_projections)\n",
        "y_training_name_index_df = pd.DataFrame(y_training_name_index)[0]\n",
        "x_test_projections_df = pd.DataFrame(x_test_projections)\n",
        "\n",
        "nbc.fit(x_training_projections_df, y_training_name_index_df)\n",
        "y_test_prediction = nbc.predict(x_test_projections_df)\n",
        "evaluate_prediction(y_test_prediction, y_test_name_index)\n",
        "print('\\n')\n",
        "\n",
        "# Training data\n",
        "print('Training data')\n",
        "x_training_projections_df = pd.DataFrame(x_training_projections)\n",
        "y_training_name_index_df = pd.DataFrame(y_training_name_index)[0]\n",
        "x_training_projections_df = pd.DataFrame(x_training_projections)\n",
        "\n",
        "nbc.fit(x_training_projections_df, y_training_name_index_df)\n",
        "y_training_prediction = nbc.predict(x_training_projections_df)\n",
        "evaluate_prediction(y_training_prediction, y_training_name_index)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Explorative Analyse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
